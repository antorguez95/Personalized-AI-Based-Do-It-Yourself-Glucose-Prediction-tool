{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from main_libreview import *\n",
    "from training_configs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path \n",
    "DATASET_PATH = r\"C:\\Users\\aralmeida\\Downloads\\LibreViewRawData\"\n",
    "\n",
    "tau = 1\n",
    "kernel_size = 3\n",
    "epochs = 1\n",
    "batch_size = 4096\n",
    "lr=0.001\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 2\n",
    "lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = testing \n",
    "dataset_path = DATASET_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch_LibreView_experiments(testing, kernel_size, tau, lr, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients with at least one year of CGM data:  29\n",
      "Dictionary loaded.\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Running experiment 1/4 for Patient #001 :\n",
      "\n",
      "Configuration:\n",
      "sensor = FreeStyle Libre X\n",
      "N = 96\n",
      "step = 1\n",
      "PH = 30\n",
      "single/multi step = multi\n",
      "partition = month-wise-4-folds\n",
      "norm = min-max\n",
      "under-over = None\n",
      "model : LSTM\n",
      "loss funcion = root_mean_squared_error\n",
      "\n",
      "Number of blocks of is 180\n",
      "\n",
      "Discarded instances: 183\n",
      "Running training using  GPU: ['device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:09:00.0, compute capability: 8.9']\n",
      "Epoch 1/2\n",
      "6479/6479 [==============================] - 35s 5ms/step - loss: 0.0030 - root_mean_squared_error: 0.0551 - ISO_adapted_loss: 0.0030\n",
      "Epoch 2/2\n",
      "6479/6479 [==============================] - 32s 5ms/step - loss: 0.0019 - root_mean_squared_error: 0.0436 - ISO_adapted_loss: 0.0019\n",
      "dict_keys(['loss', 'root_mean_squared_error', 'ISO_adapted_loss'])\n",
      "\n",
      "\tEnd of the training. Model saved in C:\\Users\\aralmeida\\Downloads\\LibreViewRawData\\1yr_npy_files\\001\\N96\\step1\\PH30\\multi\\month-wise-4-folds\\norm_min-max\\None_sampling\\LSTM\\root_mean_squared_error\\1-fold\\training\n",
      "\n",
      "132/132 [==============================] - 1s 2ms/step\n",
      "001-LSTM-1-fold Test RMSE in all time steps:   17.309359\n",
      "001-LSTM-1-fold Test MAE in all time steps:   12.261446\n",
      "001-LSTM-1-fold Test MAPE in all time steps:   8.944009244441986\n",
      "\n",
      "\n",
      "001-LSTM-1-fold Test RMSE in each time step:   [11.48472  21.617792]\n",
      "001-LSTM-1-fold Test MAE in each time step:   [ 8.467249 16.055641]\n",
      "001-LSTM-1-fold Test MAPE in each time step:   [ 6.1788106 11.709225 ]\n",
      "Running training using  GPU: ['device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:09:00.0, compute capability: 8.9']\n",
      "Epoch 1/2\n",
      "6751/6751 [==============================] - 43s 6ms/step - loss: 0.0027 - root_mean_squared_error: 0.0521 - ISO_adapted_loss: 0.0027\n",
      "Epoch 2/2\n",
      "6751/6751 [==============================] - 41s 6ms/step - loss: 0.0019 - root_mean_squared_error: 0.0432 - ISO_adapted_loss: 0.0019\n",
      "dict_keys(['loss', 'root_mean_squared_error', 'ISO_adapted_loss'])\n",
      "\n",
      "\tEnd of the training. Model saved in C:\\Users\\aralmeida\\Downloads\\LibreViewRawData\\1yr_npy_files\\001\\N96\\step1\\PH30\\multi\\month-wise-4-folds\\norm_min-max\\None_sampling\\LSTM\\root_mean_squared_error\\2-fold\\training\n",
      "\n",
      "115/115 [==============================] - 1s 2ms/step\n",
      "001-LSTM-2-fold Test RMSE in all time steps:   18.532642\n",
      "001-LSTM-2-fold Test MAE in all time steps:   11.44844\n",
      "001-LSTM-2-fold Test MAPE in all time steps:   8.804786950349808\n",
      "\n",
      "\n",
      "001-LSTM-2-fold Test RMSE in each time step:   [14.914268 21.551863]\n",
      "001-LSTM-2-fold Test MAE in each time step:   [ 7.6638002 15.233076 ]\n",
      "001-LSTM-2-fold Test MAPE in each time step:   [ 5.587843 12.02174 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aralmeida\\OneDrive - Universidad de Las Palmas de Gran Canaria\\Doctorado\\codigo\\CGM_forecasting\\tests\\..\\evaluation\\multi_step\\evaluation.py:705: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize = (20,10))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training using  GPU: ['device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:09:00.0, compute capability: 8.9']\n",
      "Epoch 1/2\n",
      "6460/6460 [==============================] - 41s 6ms/step - loss: 0.0030 - root_mean_squared_error: 0.0551 - ISO_adapted_loss: 0.0030\n",
      "Epoch 2/2\n",
      "3412/6460 [==============>...............] - ETA: 18s - loss: 0.0019 - root_mean_squared_error: 0.0437 - ISO_adapted_loss: 0.0019"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Initial time\n",
    "t0 = time.time()\n",
    "\n",
    "# From the .csv files. extract the oldest year and store them to load them separately \n",
    "get_oldest_year_npys_from_LibreView_csv(dataset_path)\n",
    "\n",
    "total_exps = len(test['sensor'])*len(test['N'])*len(test['step'])*len(test['PH'])*len(test['single_multi_step'])*len(test['partition'])*len(test['normalization'])*len(test['under_over_sampling'])*len(test['model'])*len(test['loss_function'])\n",
    "\n",
    "# Iterate over the ID folders to generate the 4-folds \n",
    "for id in os.listdir(): \n",
    "\n",
    "    # Counter \n",
    "    i = 0\n",
    "\n",
    "    # Consider only folders, not .npy or .txt files\n",
    "    if ('npy' not in id) and ('txt' not in id): \n",
    "    \n",
    "        # Get into the ID patient folder\n",
    "        os.chdir(id)\n",
    "\n",
    "        # Create dictionary to fill it with the results (one per patient) \n",
    "        results_dictionary = create_LibreView_results_dictionary()\n",
    "        dict_test = {}\n",
    "\n",
    "        # Avoid the generation of figures\n",
    "        plt.ioff()\n",
    "    \n",
    "        # Only read the OLDEST year of recording\n",
    "        recordings = np.load('oldest_1yr_CGM.npy')\n",
    "        timestamps = np.load('oldest_1yr_CGM_timestamp.npy', allow_pickle=True)\n",
    "\n",
    "        # For each patient (ID), the experiments included in \"training_configs.py\" are executed\n",
    "\n",
    "        for sensors in range(len(test['sensor'])):\n",
    "            for lengths in range(len(test['N'])):\n",
    "                for steps in range(len(test['step'])):\n",
    "                    for PHs in range(len(test['PH'])):\n",
    "                        for predic_type in range(len(test['single_multi_step'])):\n",
    "                            for partition in range(len(test['partition'])):\n",
    "                                for norm_steps in range(len(test['normalization'])):\n",
    "                                    for under_over_samp in range(len(test['under_over_sampling'])):\n",
    "                                        for model_names in range(len(test['model'])):\n",
    "                                            for loss_function in range(len(test['loss_function'])):\n",
    "                                    \n",
    "                                                # Update parameters \n",
    "                                                sensor = test['sensor'][sensors]\n",
    "                                                N = test['N'][lengths]\n",
    "                                                step = test['step'][steps]\n",
    "                                                PH = test['PH'][PHs]\n",
    "                                                single_multi_step = test['single_multi_step'][predic_type]\n",
    "                                                data_partition = test['partition'][partition]\n",
    "                                                normalization = test['normalization'][norm_steps]\n",
    "                                                under_over_sampling = test['under_over_sampling'][under_over_samp]\n",
    "                                                model_name = test['model'][model_names]\n",
    "                                                loss_function = test['loss_function'][loss_function]\n",
    "\n",
    "                                                # Create the key for current experiment \n",
    "                                                key = '{}_N{}_step{}_PH{}_{}_{}_{}_{}_{}'.format(single_multi_step, N, step, PH, data_partition, normalization,\n",
    "                                                    under_over_sampling, model_name, loss_function)\n",
    "                                                \n",
    "                                                # Declare the dictionary key empty to fill it later if it has not been created yet \n",
    "                                                if key not in results_dictionary.keys():\n",
    "                                                    results_dictionary[key] = {}\n",
    "                                                else: \n",
    "                                                    pass\n",
    "\n",
    "                                                if model_name not in results_dictionary[key].keys():\n",
    "                                                    results_dictionary[key][model_name] = {}\n",
    "                                                else:\n",
    "                                                    pass\n",
    "\n",
    "                                                # Store current working directory \n",
    "                                                cwd = os.getcwd()\n",
    "                                                \n",
    "                                                # If not created the directory correspondant with this configuration, create it\n",
    "                                                subdirectory = r\"\\N{}\\step{}\\PH{}\\{}\\{}\\norm_{}\\{}_sampling\\{}\\{}\".format(N, step, PH, single_multi_step,\n",
    "                                                                                                                        data_partition, normalization, under_over_sampling, model_name, loss_function)\n",
    "                                                if not os.path.exists(cwd+subdirectory):\n",
    "                                                    os.makedirs(cwd+subdirectory)\n",
    "                                            \n",
    "                                                # Go that subdirectory \n",
    "                                                os.chdir(cwd+subdirectory)\n",
    "\n",
    "                                                # Counter (with printing purposes)\n",
    "                                                i = i+1\n",
    "\n",
    "                                                print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~\\nRunning experiment %d/%d for Patient #%s :\\n\" % (i, total_exps, id))\n",
    "\n",
    "                                                print(\"Configuration:\\nsensor = %s\\nN = %d\\nstep = %d\\nPH = %d\\nsingle/multi step = %s\\npartition = %s\\nnorm = %s\\nunder-over = %s\\nmodel : %s\\nloss funcion = %s\\n\" \n",
    "                                                % (sensor[\"NAME\"], N, step, PH, single_multi_step, data_partition, normalization, under_over_sampling, model_name, loss_function))\n",
    "\n",
    "                                                # Generate X and Y (only multistep supportd)\n",
    "                                                if single_multi_step == 'multi':\n",
    "                                                    X, Y, X_times, Y_times = get_LibreView_CGM_X_Y_multistep(recordings, timestamps, libreview_sensors, \n",
    "                                                            N, step, PH, plot = True, verbose = 0) \n",
    "                                                else:   \n",
    "                                                    raise ValueError(\"Only 'multi' step prediction is supported in the LibreView-extracted data\")\n",
    "                                                \n",
    "                                                \n",
    "                                                # Data normalization\n",
    "                                                if normalization == 'min-max':\n",
    "                                                    X_norm = (X - np.min(X))/(np.max(X) - np.min(X))\n",
    "                                                    Y_norm = (Y - np.min(X))/(np.max(X) - np.min(X))\n",
    "                                                elif normalization == None: \n",
    "                                                    X_norm = X\n",
    "                                                    Y_norm = Y \n",
    "                                                else: \n",
    "                                                    raise ValueError(\"Not valid normalization: only 'min-max' or None are currently supported\")\n",
    "                                            \n",
    "                                                # Data partition\n",
    "                                                # 1) Month-wise 4-folds partition\n",
    "                                                if data_partition == 'month-wise-4-folds':                                                 \n",
    "                                                    training_cv_folds  = month_wise_LibreView_4fold_cv(X_norm, Y_norm, X_times, Y_times, N)\n",
    "                                                else: \n",
    "                                                    raise ValueError(\"Partition name not valid: currently 'month-wise-4-folds' is supported\")\n",
    "                                                \n",
    "                                                \n",
    "                                                # Apply (or not) undersampling or oversampling in training \n",
    "                                                if under_over_sampling == 'under':\n",
    "                                                    X_train, Y_train  = undersample_normal_range_outputs(X, X_train, Y_train, multi_step=False, normalization = normalization, undersampling_factor = 2)\n",
    "                                                elif under_over_sampling == None: \n",
    "                                                    pass\n",
    "\n",
    "                                                if single_multi_step == 'multi':\n",
    "                                                    if model_name == '1D-UNET':\n",
    "                                                        model =  get_unet1D_multi_step(sensor, \n",
    "                                                                        N=N,\n",
    "                                                                        input_features = 1,\n",
    "                                                                        tau=tau,\n",
    "                                                                        kernel_size=kernel_size, \n",
    "                                                                        PH=PH)\n",
    "                                                        model.save_weights('initial_weights.h5')\n",
    "\n",
    "                                                    elif model_name == '1D-UNET-non-compres':\n",
    "                                                        model =  get_unet1D_nonCompres_multi_step(sensor, N=N,\n",
    "                                                                        input_features = 1,\n",
    "                                                                        tau=tau,\n",
    "                                                                        kernel_size=kernel_size,\n",
    "                                                                        PH=PH)\n",
    "                                                        model.save_weights('initial_weights.h5')\n",
    "\n",
    "                                                    elif model_name == 'DIL-1D-UNET':\n",
    "                                                        model =  get_DIL_unet1D_multi_step(sensor, \n",
    "                                                                        N=N,\n",
    "                                                                        input_features = 1,\n",
    "                                                                        tau=tau,\n",
    "                                                                        kernel_size=kernel_size,\n",
    "                                                                        dilation_rate=1,\n",
    "                                                                        PH=PH)\n",
    "                                                        model.save_weights('initial_weights.h5')\n",
    "\n",
    "                                                    elif model_name == 'LSTM':\n",
    "                                                        model =  get_LSTM_multi_step(sensor, N=int(N),\n",
    "                                                                        input_features = 1, PH=PH)\n",
    "                                                        model.save_weights('initial_weights.h5')\n",
    "\n",
    "                                                    elif model_name == '1D-UNET-LSTM':\n",
    "                                                        model =  get_unet1DLSTM_multi_step(sensor, N=N,\n",
    "                                                                        input_features = 1, PH=PH)\n",
    "                                                        model.save_weights('initial_weights.h5')\n",
    "\n",
    "                                                    elif model_name == 'StackedLSTM':\n",
    "                                                        model = get_StackedLSTM_multi_step(sensor, N=int(N),\n",
    "                                                                        input_features = 1, PH=PH)\n",
    "                                                        model.save_weights('initial_weights.h5')\n",
    "                                                    elif model_name == 'naive':\n",
    "                                                        pass\n",
    "                                                    else: \n",
    "                                                        raise ValueError(\"Model name not valid\")\n",
    "                                                else: \n",
    "                                                    raise ValueError(\"Only 'multi' step prediction is supported in the LibreView-extracted data\")\n",
    "                                                \n",
    "                                                # Compute the number of predicted points that depends on the PH and the sensor sampling period\n",
    "                                                predicted_points = round(PH/sensor['SAMPLE_PERIOD'])\n",
    "\n",
    "                                                # If model is \"naive\", there is nothing to train\n",
    "                                                if model_name != 'naive':\n",
    "                                                    \n",
    "                                                    if data_partition == 'month-wise-4-folds':\n",
    "                                                        \n",
    "                                                        # Train and evaluate each folds separately \n",
    "                                                        for fold in training_cv_folds.keys():\n",
    "\n",
    "                                                            model.load_weights('initial_weights.h5')\n",
    "                                                        \n",
    "                                                            # If the directory fold is not created, create it\n",
    "                                                            if fold not in os.listdir():\n",
    "                                                                os.mkdir(fold)\n",
    "                                                            \n",
    "                                                            # Get into the fold directory\n",
    "                                                            os.chdir(fold)\n",
    "                                                            \n",
    "                                                            # One model training per fold\n",
    "                                                            train_model(sensor,\n",
    "                                                                        model,\n",
    "                                                                        X = training_cv_folds[fold]['X_train'],\n",
    "                                                                        Y = training_cv_folds[fold]['Y_train'],\n",
    "                                                                        N = N,\n",
    "                                                                        predicted_points = predicted_points,\n",
    "                                                                        epochs = epochs,\n",
    "                                                                        batch_size = batch_size,\n",
    "                                                                        lr = lr,\n",
    "                                                                        fold = id+\"-\"+model_name+\"-\"+fold,\n",
    "                                                                        loss_function = loss_function,\n",
    "                                                                        verbose = 1 \n",
    "                                                                        )\n",
    "                                                        \n",
    "                                                            # Model evaluation \n",
    "                                                            results_normal_eval = multi_step_model_evaluation(N, PH, id+\"-\"+model_name+\"-\"+fold, normalization, training_cv_folds[fold]['X_test'],\n",
    "                                                                                                            training_cv_folds[fold]['Y_test'], predicted_points, X, loss_function)\n",
    "                                                            \n",
    "                                                            # # Refeed the model with the FIRST model output to evaluate the model. Aiming to reduce final error. \n",
    "                                                            # results_refeed_eval = multi_step_model_evaluation_refeed(N, PH, model_name, normalization, X_test, Y_test, X)\n",
    "                                                            results_refeed_eval = []\n",
    "\n",
    "                                                            results_dictionary[key][model_name][fold] = {'normal ': results_normal_eval, 'refeed': results_refeed_eval}\n",
    "\n",
    "                                                            # Back to fold directory \n",
    "                                                            os.chdir('../..')\n",
    "\n",
    "                                                    else:\n",
    "                                                        raise ValueError(\"Partition name not valid: currently only 'month-wise-4-folds' training is supported\")\n",
    "\n",
    "                                                    # Back to id folder\n",
    "                                                    os.chdir(cwd)\n",
    "\n",
    "                                                    # Save updated dictionary \n",
    "                                                    with open('results_dictionary.json', 'w') as fp:\n",
    "                                                        json.dump(results_dictionary, fp)                                                      \n",
    "\n",
    "                                                    # Back to previous directory \n",
    "                                                    os.chdir('..')\n",
    "\n",
    "                                                elif model_name == 'naive':\n",
    "                                                    print(\"Naive model evaluation. Training step not needed. Only evaluation is performed\")\n",
    "\n",
    "                                                    # Do the naive prediction in all folds \n",
    "                                                    for fold in training_cv_folds.keys():\n",
    "                                                        \n",
    "                                                            # If the directory fold is not created, create it\n",
    "                                                            if fold not in os.listdir():\n",
    "                                                                os.mkdir(fold)\n",
    "                                                            \n",
    "                                                            # Get into the fold directory\n",
    "                                                            os.chdir(fold)\n",
    "\n",
    "                                                            if single_multi_step == 'multi':\n",
    "\n",
    "                                                                # Non-refeed evaluation\n",
    "                                                                results_normal_eval = multi_step_model_evaluation(N, PH, id+\"-\"+model_name+\"-\"+fold, normalization, training_cv_folds[fold]['X_test'],\n",
    "                                                                                                            training_cv_folds[fold]['Y_test'], predicted_points, X, loss_function)\n",
    "                                                                # os.chdir('..')\n",
    "\n",
    "                                                                # # Refeed the model with the FIRST model output to evaluate the model. Aiming to reduce final error. \n",
    "                                                                # results_refeed_eval = multi_step_model_evaluation_refeed(N, PH, model_name, normalization, X_test, Y_test, X)\n",
    "                                                                results_refeed_eval = []\n",
    "\n",
    "                                                                results_dictionary[key][model_name][fold] = {'normal ': results_normal_eval, 'refeed': results_refeed_eval}\n",
    "                                                                \n",
    "                                                                # Back to previous directory \n",
    "                                                                os.chdir('../..')\n",
    "                                                    \n",
    "                                                            else: \n",
    "                                                                raise ValueError(\"Only 'multi' step prediction is supported in the LibreView-extracted data\")\n",
    "                                                            \n",
    "                                                    # Back to id folder\n",
    "                                                    os.chdir(cwd)\n",
    "\n",
    "                                                    # Save updated dictionary \n",
    "                                                    with open('results_dictionary.json', 'w') as fp:\n",
    "                                                        json.dump(results_dictionary, fp)                                                      \n",
    "\n",
    "                                                    # Back to previous directory \n",
    "                                                    os.chdir('..')\n",
    "                                                \n",
    "                                                else: \n",
    "                                                    raise ValueError(\"Model name not valid\")\n",
    "\n",
    "    # Stop when the counter is equal to the total number of experiments\n",
    "    if i == total_exps*29: # 29 is the number of patients\n",
    "        break\n",
    "\n",
    "# Final time\n",
    "t1 = time.time()\n",
    "print(\"Time elapsed: %d seconds\" % (t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(PH/sensor[\"SAMPLE_PERIOD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "T1DM_WARIFA_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
