{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sys\n",
    "from typing import Dict \n",
    "import matplotlib.pyplot as plt \n",
    "import openpyxl\n",
    "import pickle\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from libreview_utils import *\n",
    "from models.training import *\n",
    "from sensor_params import *\n",
    "from utils import get_LibreView_CGM_X_Y_multistep\n",
    "\n",
    "from models.multi_step.StackedLSTM import get_model as get_StackedLSTM_multi_step\n",
    "\n",
    "from evaluation.multi_step.evaluation import model_evaluation as multi_step_model_evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path \n",
    "DATASET_PATH = r\"C:\\Users\\aralmeida\\Downloads\\LibreViewRawData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "sensor = libreview_sensors\n",
    "N = 48\n",
    "step = 1\n",
    "verbose = 0\n",
    "PH = 60\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 4096\n",
    "lr=0.001\n",
    "model_name = 'StackedLSTM'\n",
    "loss_function = 'root_mean_squared_error'\n",
    "\n",
    "normalization = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients with at least one year of CGM data:  29\n"
     ]
    }
   ],
   "source": [
    "# # Go to the dataset directory \n",
    "# os.chdir(DATASET_PATH)\n",
    "\n",
    "# # Read .csv or load the pickle file that contains the dictionary to avoid .csv slower reading \n",
    "# if 'libreview_data.pickle' in os.listdir():\n",
    "#     with open('libreview_data.pickle', 'rb') as handle:\n",
    "#         libreview_data = pickle.load(handle) # Previously generated with prepare_LibreView_data(DATASET_PATH)\n",
    "# else: \n",
    "#     # If the dictionary has not been created, read the .csv files\n",
    "#     libreview_data = prepare_LibreView_data(DATASET_PATH)\n",
    "\n",
    "\n",
    "# # Take only the T1DM patients with at least one year in a row of CGM data with the same sensor \n",
    "# data_1yr_recordings = get_1year_LibreView_recordings_dict(libreview_data)\n",
    "\n",
    "# # Generate the Libreview .npy files from the generated or saved dictionary \n",
    "# generate_LibreView_npy_files(data_1yr_recordings, r\"/1yr_npy_files\")\n",
    "\n",
    "# # Extract an EXACT 1 year recordings from the dictionary and store them to load them separately \n",
    "# generate_LibreView_npy_1yr_recordings(data_1yr_recordings)\n",
    "\n",
    "# Extract an EXACT 1 year recordings from the dictionary and store them to load them separately \n",
    "get_oldest_year_npys_from_LibreView_csv(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the ID folders to generate the 4-folds \n",
    "for id in os.listdir(): \n",
    "    \n",
    "    # Consider only folders, not .npy or .txt files\n",
    "    if ('npy' not in id) and ('txt' not in id): \n",
    "    \n",
    "        # Get into the ID patient folder\n",
    "        os.chdir(id)\n",
    "    \n",
    "        # Only read the OLDEST year of recording\n",
    "        recordings = np.load('oldest_1yr_CGM.npy')\n",
    "        timestamps = np.load('oldest_1yr_CGM_timestamp.npy', allow_pickle=True)\n",
    "\n",
    "        print(\"PATIENT :\", id)\n",
    "\n",
    "        X, Y, X_times, Y_times = get_LibreView_CGM_X_Y_multistep(recordings, timestamps, libreview_sensors, \n",
    "                                    N, step, PH, plot = True,\n",
    "                                    verbose = 0)\n",
    "        \n",
    "        # Print shapes of the generated X and Y\n",
    "        print(\"X shape: \", X.shape)\n",
    "        print(\"Y shape: \", Y.shape, \"\\n\")\n",
    "        print(\"~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "        # Min-max normalization\n",
    "        # X = min_max_normalization(X)\n",
    "        # Y = min_max_normalization(Y)\n",
    "\n",
    "        # month-wise 4-folds partition \n",
    "        training_cv_folds  = month_wise_LibreView_4fold_cv(X, Y, X_times, Y_times, 48)\n",
    "\n",
    "        # Load model \n",
    "        model = get_StackedLSTM_multi_step(sensor, N=int(N),\n",
    "                input_features = 1, PH=PH)\n",
    "        \n",
    "        predicted_points = PH/sensor['SAMPLE_PERIOD']\n",
    "\n",
    "        for fold in training_cv_folds.keys():\n",
    "            \n",
    "            # If the directory fold is not created, create it\n",
    "            if fold not in os.listdir():\n",
    "                os.mkdir(fold)\n",
    "            \n",
    "            # Get into the fold directory\n",
    "            os.chdir(fold)\n",
    "            \n",
    "            # One model training per fold\n",
    "            train_model(sensor,\n",
    "                        model,\n",
    "                        X = training_cv_folds[fold]['X_train'],\n",
    "                        Y = training_cv_folds[fold]['Y_train'],\n",
    "                        N = N,\n",
    "                        predicted_points = predicted_points,\n",
    "                        epochs = epochs,\n",
    "                        batch_size = batch_size,\n",
    "                        lr = lr,\n",
    "                        fold = id+\"-\"+model_name+\"-\"+fold,\n",
    "                        loss_function = loss_function,\n",
    "                        verbose = 1 \n",
    "                        )\n",
    "\n",
    "            # Model evaluation \n",
    "            results_normal_eval = multi_step_model_evaluation(N, PH, id+\"-\"+model_name+\"-\"+fold, normalization, training_cv_folds[fold]['X_test'],\n",
    "                                                            training_cv_folds[fold]['Y_test'], predicted_points, X, loss_function)\n",
    "\n",
    "            # Back to the parent directory \n",
    "            os.chdir('../../..')\n",
    "\n",
    "        # Back to previous directory \n",
    "        os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking if we are actually taking the oldest 1-year recording "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop over all the patients, read the recording and timestamps and generate the 4-folds\n",
    "# for id in os.listdir(): \n",
    "\n",
    "#     # Only consider folders, not .npy files \n",
    "#     if '.npy' not in id: \n",
    "    \n",
    "#         # Get into the patient folder \n",
    "#         os.chdir(id) \n",
    "\n",
    "#         print(id)\n",
    "\n",
    "#         # Load the oldest year and timestamps \n",
    "#         cgm = np.load('oldest_1yr_CGM.npy')\n",
    "#         timestamps = np.load('oldest_1yr_CGM_timestamp.npy', allow_pickle=True)\n",
    "#         print(\"Samples length: \", len(cgm), \"Timestamps length: \", len(timestamps))\n",
    "#         print(\"Fist timestamp: \", timestamps[0], \"Last timestamp: \", timestamps[-1], \"\\n\")\n",
    "\n",
    "#         # Back to parent directory \n",
    "#         os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking that we are taking the oldest reading considering the MAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example with the ID 004\n",
    "# id = '004'\n",
    "# s = '001'\n",
    "# r = '001'\n",
    "# data = '10-7-2023'\n",
    "\n",
    "# # id = '014'\n",
    "# # s = '001'\n",
    "# # r = '001'\n",
    "# # data = '10-7-2023'\n",
    "\n",
    "# id = '046'\n",
    "# s = '001'\n",
    "# r = '001'\n",
    "# data = '11-7-2023'\n",
    "\n",
    "# # Counter\n",
    "# iter = 0\n",
    "\n",
    "# for mac in data_1yr_recordings[id][s][r][data].keys():\n",
    "        \n",
    "#     # Each MAC is uniquely joint to a sensor\n",
    "#     sensor = list(data_1yr_recordings[id][s][r][data][mac].keys())[0]\n",
    "\n",
    "#     # Refresh current MAC-associated date\n",
    "#     first_date_current_mac = data_1yr_recordings[id][s][r][data][mac][sensor]['CGM']['timestamp'][0]\n",
    "#     print(first_date_current_mac, \": \", mac)\n",
    "\n",
    "#     if iter == 0:\n",
    "#         oldest_mac = mac\n",
    "#         oldest_mac_first_date = first_date_current_mac\n",
    "#         iter = iter+1\n",
    "    \n",
    "#     else: \n",
    "#         if (first_date_current_mac <= oldest_mac_first_date):\n",
    "#             print(first_date_current_mac)\n",
    "#             print(\"<\")\n",
    "#             print(oldest_mac_first_date)\n",
    "#             oldest_mac = mac\n",
    "#             oldest_mac_first_date = first_date_current_mac\n",
    "#             iter = iter+1\n",
    "#         else: \n",
    "#             # MAC remains the same as before\n",
    "#             oldest_mac = oldest_mac \n",
    "#             oldest_mac_first_date = oldest_mac_first_date\n",
    "#             iter = iter+1\n",
    "\n",
    "# # Sensor associated to the oldest MAC\n",
    "# sensor = list(data_1yr_recordings[id][s][r][data][oldest_mac].keys())[0]\n",
    "\n",
    "# # Extract CGM recordings of the oldest MAC and their correspondant timestamps \n",
    "# recordings = data_1yr_recordings[id][s][r][data][oldest_mac][sensor]['CGM']['reading']\n",
    "# recordings_timestamps = data_1yr_recordings[id][s][r][data][oldest_mac][sensor]['CGM']['timestamp']\n",
    "        \n",
    "# # Save as .npy files\n",
    "# os.chdir(id)\n",
    "# np.save('oldest_1yr_CGM.npy', recordings)\n",
    "# np.save('oldest_1yr_CGM_timestamp.npy', recordings_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def month_wise_LibreView_4fold_cv(X: np.array, Y: np.array, X_times : np.array, Y_times : np.array, N: int) -> Dict:\n",
    "\n",
    "#     \"\"\"\n",
    "#     This function partitions the data in 4 folds. Each fold contains data from 3 months of the same year.\n",
    "#     With this, each model is trained and validated with all different terms in a year. The timestamps \n",
    "#     of the folds will vary depending on the patient. The oldest recorded sample in the patient will be the \n",
    "#     first sample of the first fold. The first sample of the second fold will be that sample plus 3 months,\n",
    "#     and so on. This function has been designed to work with LibreView-extracted data, but can be adapted to \n",
    "#     other data sources. Information about the partitions is stored in a .txt file.\n",
    "\n",
    "#     Data is stored in its correspondant fold in the dictionary training_partitions.\n",
    "\n",
    "#     Args:\n",
    "#     -----\n",
    "#         X: input sequence of lenght N.\n",
    "#         Y: output sequence.\n",
    "#         X_times: timestamps of the input sequence.\n",
    "#         Y_times: timestamps of the output sequence.\n",
    "#         N: window size of the input data.\n",
    "#         shuffle: flag that indicates whether to shuffle the data or not.\n",
    "#         verbose: verbosity level. \n",
    "\n",
    "#     Returns:\n",
    "#     --------\n",
    "#         folds_dict: dictionary containing the 4 folds. Each fold contains the training and validation sets.\n",
    "    \n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Declare the dictionary to intuitively access the folds \n",
    "#     folds_dict = {'1-fold' : {'X_train' : {},\n",
    "#                             'Y_train' : {},\n",
    "#                             'X_test' : {},\n",
    "#                             'Y_test' : {}},\n",
    "#                 '2-fold' : {'X_train' : {},\n",
    "#                             'Y_train' : {},\n",
    "#                             'X_test' : {},\n",
    "#                             'Y_test' : {}},            \n",
    "#                 '3-fold' : {'X_train' : {},\n",
    "#                             'Y_train' : {},\n",
    "#                             'X_test' : {},\n",
    "#                             'Y_test' : {}},\n",
    "#                 '4-fold' : {'X_train' : {},\n",
    "#                             'Y_train' : {},\n",
    "#                             'X_test' : {},\n",
    "#                             'Y_test' : {}}}\n",
    "    \n",
    "#     # Timestamp of the fold 1 is the first of the whole recording \n",
    "#     fold1_first_timestamp = X_times[0][0]\n",
    "\n",
    "#     # Timestamp of the fold 2 is the first of the whole recording + 3 months\n",
    "#     fold2_first_timestamp = fold1_first_timestamp + pd.DateOffset(months=3)\n",
    "\n",
    "#     # Timestamp of the fold 3 is the first of the whole recording + 6 months\n",
    "#     fold3_first_timestamp = fold1_first_timestamp + pd.DateOffset(months=6)\n",
    "\n",
    "#     # Timestamp of the fold 4 is the first of the whole recording + 9 months\n",
    "#     fold4_first_timestamp = fold1_first_timestamp + pd.DateOffset(months=9)\n",
    "\n",
    "#     # With the timestamps, the 4 folds are generated\n",
    "#     X_fold1 = X[np.where((X_times[:,0] >= fold1_first_timestamp) & (Y_times[:,0] < fold2_first_timestamp))[0]]\n",
    "#     X_fold2 = X[np.where((X_times[:,0] >= fold2_first_timestamp) & (Y_times[:,0] < fold3_first_timestamp))[0]]\n",
    "#     X_fold3 = X[np.where((X_times[:,0] >= fold3_first_timestamp) & (Y_times[:,0] < fold4_first_timestamp))[0]]\n",
    "#     X_fold4 = X[np.where(X_times[:,0] >= fold4_first_timestamp)] \n",
    "\n",
    "#     # Also save the timestamps of the fold just in case they are necessary \n",
    "#     X_times_fold1 = X_times[np.where((X_times[:,0] >= fold1_first_timestamp) & (Y_times[:,0] < fold2_first_timestamp))[0]]\n",
    "#     X_times_fold2 = X_times[np.where((X_times[:,0] >= fold2_first_timestamp) & (Y_times[:,0] < fold3_first_timestamp))[0]]\n",
    "#     X_times_fold3 = X_times[np.where((X_times[:,0] >= fold3_first_timestamp) & (Y_times[:,0] < fold4_first_timestamp))[0]]\n",
    "#     X_times_fold4 = X_times[np.where(X_times[:,0] >= fold4_first_timestamp)]\n",
    "\n",
    "#     # Take the same instances from Y\n",
    "#     Y_fold1 = Y[np.where((X_times[:,0] >= fold1_first_timestamp) & (Y_times[:,0] < fold2_first_timestamp))[0]]\n",
    "#     Y_fold2 = Y[np.where((X_times[:,0] >= fold2_first_timestamp) & (Y_times[:,0] < fold3_first_timestamp))[0]]\n",
    "#     Y_fold3 = Y[np.where((X_times[:,0] >= fold3_first_timestamp) & (Y_times[:,0] < fold4_first_timestamp))[0]]\n",
    "#     Y_fold4 = Y[np.where(X_times[:,0] >= fold4_first_timestamp)]\n",
    "\n",
    "#     # Take the same instances from Y_times\n",
    "#     Y_times_fold1 = Y_times[np.where((X_times[:,0] >= fold1_first_timestamp) & (Y_times[:,0] < fold2_first_timestamp))[0]]\n",
    "#     Y_times_fold2 = Y_times[np.where((X_times[:,0] >= fold2_first_timestamp) & (Y_times[:,0] < fold3_first_timestamp))[0]]\n",
    "#     Y_times_fold3 = Y_times[np.where((X_times[:,0] >= fold3_first_timestamp) & (Y_times[:,0] < fold4_first_timestamp))[0]]\n",
    "#     Y_times_fold4 = Y_times[np.where(X_times[:,0] >= fold4_first_timestamp)]\n",
    "\n",
    "#     lost_samples = len(X) - (len(X_fold1) + len(X_fold2) + len(X_fold3) + len(X_fold4))\n",
    "\n",
    "#     print(\"Discarded instances for %i\" % (lost_samples))\n",
    "\n",
    "#     # Save valuable information in a .txt file\n",
    "#     with open('4-folds_summary.txt', 'w') as f:\n",
    "#         f.write('1-fold start date = {}\\n'.format(fold1_first_timestamp))\n",
    "#         f.write('1-fold num. samples = {}\\n\\n'.format(len(X_fold1)))\n",
    "\n",
    "#         f.write('2-fold start date = {}\\n'.format(fold2_first_timestamp))\n",
    "#         f.write('2-fold num. samples = {}\\n\\n'.format(len(X_fold2)))\n",
    "\n",
    "#         f.write('3-fold start date = {}\\n'.format(fold3_first_timestamp))\n",
    "#         f.write('3-fold num. samples = {}\\n\\n'.format(len(X_fold3)))\n",
    "\n",
    "#         f.write('4-fold start date = {}\\n'.format(fold4_first_timestamp))\n",
    "#         f.write('4-fold num. samples = {}\\n\\n'.format(len(X_fold4)))\n",
    "\n",
    "#         f.write('Discarded instances due to overlap = {}\\n'.format(lost_samples))\n",
    "\n",
    "#     # Concatenate XY in the same array but in a different axis. Just once to shuflle later \n",
    "#     XY_fold1 = np.concatenate((X_fold1, Y_fold1), axis=1)\n",
    "#     XY_fold2 = np.concatenate((X_fold2, Y_fold2), axis=1)\n",
    "#     XY_fold3 = np.concatenate((X_fold3, Y_fold3), axis=1)\n",
    "#     XY_fold4 = np.concatenate((X_fold4, Y_fold4), axis=1)\n",
    "\n",
    "#     # Create the training sets for each fold \n",
    "#     fold1_XY_train_set = np.concatenate((XY_fold1, XY_fold2, XY_fold3), axis=0)\n",
    "#     fold2_XY_train_set = np.concatenate((XY_fold1, XY_fold2, XY_fold4), axis=0)\n",
    "#     fold3_XY_train_set = np.concatenate((XY_fold1, XY_fold3, XY_fold4), axis=0)\n",
    "#     fold4_XY_train_set = np.concatenate((XY_fold2, XY_fold3, XY_fold4), axis=0)\n",
    "\n",
    "#     # Shuffle the training sets\n",
    "#     np.random.shuffle(fold1_XY_train_set)\n",
    "#     np.random.shuffle(fold2_XY_train_set)\n",
    "#     np.random.shuffle(fold3_XY_train_set)\n",
    "#     np.random.shuffle(fold4_XY_train_set)\n",
    "\n",
    "#     # Split the training sets into X and Y\n",
    "#     fold1_X_train = fold1_XY_train_set[:,0:N]\n",
    "#     fold1_Y_train = fold1_XY_train_set[:,N:]\n",
    "\n",
    "#     fold2_X_train = fold2_XY_train_set[:,0:N]\n",
    "#     fold2_Y_train = fold2_XY_train_set[:,N:]\n",
    "\n",
    "#     fold3_X_train = fold3_XY_train_set[:,0:N]\n",
    "#     fold3_Y_train = fold3_XY_train_set[:,N:]\n",
    "\n",
    "#     fold4_X_train = fold4_XY_train_set[:,0:N]\n",
    "#     fold4_Y_train = fold4_XY_train_set[:,N:]\n",
    "\n",
    "#     # Fill the dictionary fold-wise\n",
    "#     # 1-fold\n",
    "#     folds_dict['1-fold']['X_train'] = fold1_X_train\n",
    "#     folds_dict['1-fold']['Y_train'] = fold1_Y_train\n",
    "#     folds_dict['1-fold']['X_test'] = X_fold4\n",
    "#     folds_dict['1-fold']['Y_test'] = Y_fold4\n",
    "\n",
    "#     # 2-fold\n",
    "#     folds_dict['2-fold']['X_train'] = fold2_X_train\n",
    "#     folds_dict['2-fold']['Y_train'] = fold2_Y_train\n",
    "#     folds_dict['2-fold']['X_test'] = X_fold3\n",
    "#     folds_dict['2-fold']['Y_test'] = Y_fold3\n",
    "\n",
    "#     # 3-fold\n",
    "#     folds_dict['3-fold']['X_train'] = fold3_X_train\n",
    "#     folds_dict['3-fold']['Y_train'] = fold3_Y_train\n",
    "#     folds_dict['3-fold']['X_test'] = X_fold2\n",
    "#     folds_dict['3-fold']['Y_test'] = Y_fold2\n",
    "\n",
    "#     # 4-fold\n",
    "#     folds_dict['3-fold']['X_train'] = fold4_X_train\n",
    "#     folds_dict['3-fold']['Y_train'] = fold4_Y_train\n",
    "#     folds_dict['3-fold']['X_test'] = X_fold1\n",
    "#     folds_dict['3-fold']['Y_test'] = Y_fold1\n",
    "\n",
    "#     return folds_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over the ID folders to generate the 4-folds \n",
    "# for id in os.listdir(): \n",
    "    \n",
    "#     # Consider only folders, not .npy or .txt files\n",
    "#     if ('npy' not in id) and ('txt' not in id): \n",
    "    \n",
    "#         # Get into the ID patient folder\n",
    "#         os.chdir(id)\n",
    "    \n",
    "#         # Only read the OLDEST year of recording\n",
    "#         recordings = np.load('oldest_1yr_CGM.npy')\n",
    "#         timestamps = np.load('oldest_1yr_CGM_timestamp.npy', allow_pickle=True)\n",
    "\n",
    "#         print(\"PATIENT :\", id)\n",
    "\n",
    "#         X, Y, X_times, Y_times = get_LibreView_CGM_X_Y_multistep(recordings, timestamps, libreview_sensors, \n",
    "#                                     48, 1, 60, plot = True,\n",
    "#                                     verbose = 0)\n",
    "        \n",
    "#         # Print shapes of the generated X and Y\n",
    "#         print(\"X shape: \", X.shape)\n",
    "#         print(\"Y shape: \", Y.shape, \"\\n\")\n",
    "#         print(\"~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "#         # Min-max normalization\n",
    "#         # X = min_max_normalization(X)\n",
    "#         # Y = min_max_normalization(Y)\n",
    "\n",
    "#         # month-wise 4-folds partition \n",
    "#         training_cv_folds  = month_wise_LibreView_4fold_cv(X, Y, X_times, Y_times, 48)\n",
    "\n",
    "#         # Load model \n",
    "#         model = get_StackedLSTM_multi_step(sensor, N=int(N),\n",
    "#                 input_features = 1, PH=PH)\n",
    "        \n",
    "#         predicted_points = PH/sensor['SAMPLE_PERIOD']\n",
    "\n",
    "#         for fold in training_cv_folds.keys():\n",
    "            \n",
    "#             # If the directory fold is not created, create it\n",
    "#             if fold not in os.listdir():\n",
    "#                 os.mkdir(fold)\n",
    "            \n",
    "#             # Get into the fold directory\n",
    "#             os.chdir(fold)\n",
    "            \n",
    "#             # One model training per fold\n",
    "#             train_model(sensor,\n",
    "#                         model,\n",
    "#                         X = training_cv_folds[fold]['X_train'],\n",
    "#                         Y = training_cv_folds[fold]['Y_train'],\n",
    "#                         N = N,\n",
    "#                         predicted_points = predicted_points,\n",
    "#                         epochs = epochs,\n",
    "#                         batch_size = batch_size,\n",
    "#                         lr = lr,\n",
    "#                         fold = id+\"-\"+model_name+\"-\"+fold,\n",
    "#                         loss_function = loss_function,\n",
    "#                         verbose = 1 \n",
    "#                         )\n",
    "\n",
    "#             # Model evaluation \n",
    "#             results_normal_eval = multi_step_model_evaluation(N, PH, id+\"-\"+model_name+\"-\"+fold, normalization, training_cv_folds[fold]['X_test'],\n",
    "#                                                             training_cv_folds[fold]['Y_test'], predicted_points, X, loss_function)\n",
    "\n",
    "#             # Back to the parent directory \n",
    "#             os.chdir('../../..')\n",
    "\n",
    "#         # Back to previous directory \n",
    "#         os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the new 4 folds function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing bugs in 4 months wise function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over the ID folders to generate the 4-folds \n",
    "# for id in os.listdir(): \n",
    "    \n",
    "#     # Consider only folders, not .npy or .txt files\n",
    "#     if ('npy' not in id) and ('txt' not in id): \n",
    "    \n",
    "#         # Get into the ID patient folder\n",
    "#         os.chdir(id)\n",
    "    \n",
    "#         # Only read the OLDEST year of recording\n",
    "#         recordings = np.load('oldest_1yr_CGM.npy')\n",
    "#         timestamps = np.load('oldest_1yr_CGM_timestamp.npy', allow_pickle=True)\n",
    "\n",
    "#         print(\"PATIENT :\", id)\n",
    "\n",
    "#         X, Y, X_times, Y_times = get_LibreView_CGM_X_Y_multistep(recordings, timestamps, libreview_sensors, \n",
    "#                                     48, 1, 60, plot = False,\n",
    "#                                     verbose = 0)\n",
    "        \n",
    "#         # Print shapes of the generated X and Y\n",
    "#         # print(\"X shape: \", X.shape)\n",
    "#         # print(\"Y shape: \", Y.shape, \"\\n\")\n",
    "#         # print(\"~~~~~~~~~~~~~~~~~~\")   \n",
    "\n",
    "#         # Declare the dictionary to intuitively access the folds \n",
    "#         folds_dict = {'1-fold' : {'X_train' : {},\n",
    "#                                 'Y_train' : {},\n",
    "#                                 'X_test' : {},\n",
    "#                                 'Y_test' : {}},\n",
    "#                     '2-fold' : {'X_train' : {},\n",
    "#                                 'Y_train' : {},\n",
    "#                                 'X_test' : {},\n",
    "#                                 'Y_test' : {}},            \n",
    "#                     '3-fold' : {'X_train' : {},\n",
    "#                                 'Y_train' : {},\n",
    "#                                 'X_test' : {},\n",
    "#                                 'Y_test' : {}},\n",
    "#                     '4-fold' : {'X_train' : {},\n",
    "#                                 'Y_train' : {},\n",
    "#                                 'X_test' : {},\n",
    "#                                 'Y_test' : {}}}\n",
    "        \n",
    "#         # Timestamp of the fold 1 is the first of the whole recording \n",
    "#         fold1_first_timestamp = X_times[0][0]\n",
    "\n",
    "#         # Timestamp of the fold 2 is the first of the whole recording + 3 months\n",
    "#         fold2_first_timestamp = fold1_first_timestamp + pd.DateOffset(months=3)\n",
    "\n",
    "#         # Timestamp of the fold 3 is the first of the whole recording + 6 months\n",
    "#         fold3_first_timestamp = fold1_first_timestamp + pd.DateOffset(months=6)\n",
    "\n",
    "#         # Timestamp of the fold 4 is the first of the whole recording + 9 months\n",
    "#         fold4_first_timestamp = fold1_first_timestamp + pd.DateOffset(months=9)\n",
    "\n",
    "#         # With the timestamps, the 4 folds are generated\n",
    "#         X_fold1 = X[np.where((X_times[:,0] >= fold1_first_timestamp) & (Y_times[:,0] < fold2_first_timestamp))[0]]\n",
    "#         X_fold2 = X[np.where((X_times[:,0] >= fold2_first_timestamp) & (Y_times[:,0] < fold3_first_timestamp))[0]]\n",
    "#         X_fold3 = X[np.where((X_times[:,0] >= fold3_first_timestamp) & (Y_times[:,0] < fold4_first_timestamp))[0]]\n",
    "#         X_fold4 = X[np.where(X_times[:,0] >= fold4_first_timestamp)] \n",
    "\n",
    "#         # Also save the timestamps of the fold just in case they are necessary \n",
    "#         X_times_fold1 = X_times[np.where((X_times[:,0] >= fold1_first_timestamp) & (Y_times[:,0] < fold2_first_timestamp))[0]]\n",
    "#         X_times_fold2 = X_times[np.where((X_times[:,0] >= fold2_first_timestamp) & (Y_times[:,0] < fold3_first_timestamp))[0]]\n",
    "#         X_times_fold3 = X_times[np.where((X_times[:,0] >= fold3_first_timestamp) & (Y_times[:,0] < fold4_first_timestamp))[0]]\n",
    "#         X_times_fold4 = X_times[np.where(X_times[:,0] >= fold4_first_timestamp)]\n",
    "\n",
    "#         # Take the same instances from Y\n",
    "#         Y_fold1 = Y[np.where((X_times[:,0] >= fold1_first_timestamp) & (Y_times[:,0] < fold2_first_timestamp))[0]]\n",
    "#         Y_fold2 = Y[np.where((X_times[:,0] >= fold2_first_timestamp) & (Y_times[:,0] < fold3_first_timestamp))[0]]\n",
    "#         Y_fold3 = Y[np.where((X_times[:,0] >= fold3_first_timestamp) & (Y_times[:,0] < fold4_first_timestamp))[0]]\n",
    "#         Y_fold4 = Y[np.where(X_times[:,0] >= fold4_first_timestamp)]\n",
    "\n",
    "#         # Take the same instances from Y_times\n",
    "#         Y_times_fold1 = Y_times[np.where((X_times[:,0] >= fold1_first_timestamp) & (Y_times[:,0] < fold2_first_timestamp))[0]]\n",
    "#         Y_times_fold2 = Y_times[np.where((X_times[:,0] >= fold2_first_timestamp) & (Y_times[:,0] < fold3_first_timestamp))[0]]\n",
    "#         Y_times_fold3 = Y_times[np.where((X_times[:,0] >= fold3_first_timestamp) & (Y_times[:,0] < fold4_first_timestamp))[0]]\n",
    "#         Y_times_fold4 = Y_times[np.where(X_times[:,0] >= fold4_first_timestamp)]\n",
    "\n",
    "#         lost_samples = len(X) - (len(X_fold1) + len(X_fold2) + len(X_fold3) + len(X_fold4))\n",
    "\n",
    "#         # print(\"Discarded instances: %i\" % (lost_samples))\n",
    "\n",
    "#         # Save valuable information in a .txt file\n",
    "#         with open('4-folds_summary.txt', 'w') as f:\n",
    "#             f.write('1-fold start date = {}\\n'.format(fold1_first_timestamp))\n",
    "#             f.write('1-fold num. samples = {}\\n\\n'.format(len(X_fold1)))\n",
    "\n",
    "#             f.write('2-fold start date = {}\\n'.format(fold2_first_timestamp))\n",
    "#             f.write('2-fold num. samples = {}\\n\\n'.format(len(X_fold2)))\n",
    "\n",
    "#             f.write('3-fold start date = {}\\n'.format(fold3_first_timestamp))\n",
    "#             f.write('3-fold num. samples = {}\\n\\n'.format(len(X_fold3)))\n",
    "\n",
    "#             f.write('4-fold start date = {}\\n'.format(fold4_first_timestamp))\n",
    "#             f.write('4-fold num. samples = {}\\n\\n'.format(len(X_fold4)))\n",
    "\n",
    "#             f.write('Discarded instances due to overlap = {}\\n'.format(lost_samples))\n",
    "\n",
    "#         # Concatenate XY in the same array but in a different axis. Just once to shuflle later \n",
    "#         XY_fold1 = np.concatenate((X_fold1, Y_fold1), axis=1)\n",
    "#         XY_fold2 = np.concatenate((X_fold2, Y_fold2), axis=1)\n",
    "#         XY_fold3 = np.concatenate((X_fold3, Y_fold3), axis=1)\n",
    "#         XY_fold4 = np.concatenate((X_fold4, Y_fold4), axis=1)\n",
    "\n",
    "#         # Create the training sets for each fold \n",
    "#         fold1_XY_train_set = np.concatenate((XY_fold1, XY_fold2, XY_fold3), axis=0)\n",
    "#         fold2_XY_train_set = np.concatenate((XY_fold1, XY_fold2, XY_fold4), axis=0)\n",
    "#         fold3_XY_train_set = np.concatenate((XY_fold1, XY_fold3, XY_fold4), axis=0)\n",
    "#         fold4_XY_train_set = np.concatenate((XY_fold2, XY_fold3, XY_fold4), axis=0)\n",
    "\n",
    "#         # Shuffle the training sets\n",
    "#         np.random.shuffle(fold1_XY_train_set)\n",
    "#         np.random.shuffle(fold2_XY_train_set)\n",
    "#         np.random.shuffle(fold3_XY_train_set)\n",
    "#         np.random.shuffle(fold4_XY_train_set)\n",
    "\n",
    "#         # Split the training sets into X and Y\n",
    "#         fold1_X_train = fold1_XY_train_set[:,0:N]\n",
    "#         fold1_Y_train = fold1_XY_train_set[:,N:]\n",
    "\n",
    "#         fold2_X_train = fold2_XY_train_set[:,0:N]\n",
    "#         fold2_Y_train = fold2_XY_train_set[:,N:]\n",
    "\n",
    "#         fold3_X_train = fold3_XY_train_set[:,0:N]\n",
    "#         fold3_Y_train = fold3_XY_train_set[:,N:]\n",
    "\n",
    "#         fold4_X_train = fold4_XY_train_set[:,0:N]\n",
    "#         fold4_Y_train = fold4_XY_train_set[:,N:]\n",
    "\n",
    "#         # Fill the dictionary fold-wise\n",
    "#         # 1-fold\n",
    "#         folds_dict['1-fold']['X_train'] = fold1_X_train\n",
    "#         folds_dict['1-fold']['Y_train'] = fold1_Y_train\n",
    "#         folds_dict['1-fold']['X_test'] = X_fold4\n",
    "#         folds_dict['1-fold']['Y_test'] = Y_fold4\n",
    "\n",
    "#         # 2-fold\n",
    "#         folds_dict['2-fold']['X_train'] = fold2_X_train\n",
    "#         folds_dict['2-fold']['Y_train'] = fold2_Y_train\n",
    "#         folds_dict['2-fold']['X_test'] = X_fold3\n",
    "#         folds_dict['2-fold']['Y_test'] = Y_fold3\n",
    "\n",
    "#         # 3-fold\n",
    "#         folds_dict['3-fold']['X_train'] = fold3_X_train\n",
    "#         folds_dict['3-fold']['Y_train'] = fold3_Y_train\n",
    "#         folds_dict['3-fold']['X_test'] = X_fold2\n",
    "#         folds_dict['3-fold']['Y_test'] = Y_fold2\n",
    "\n",
    "#         # 4-fold\n",
    "#         folds_dict['4-fold']['X_train'] = fold4_X_train\n",
    "#         folds_dict['4-fold']['Y_train'] = fold4_Y_train\n",
    "#         folds_dict['4-fold']['X_test'] = X_fold1\n",
    "#         folds_dict['4-fold']['Y_test'] = Y_fold1\n",
    "\n",
    "#         for fold in folds_dict.keys():\n",
    "#             for sets in folds_dict[fold].keys():\n",
    "#                 print(fold, sets, len(folds_dict[fold][sets]))\n",
    "#                 if len(folds_dict[fold][sets]) == 0:\n",
    "#                     print(fold, id, \" --> EMPTY\")\n",
    "                    \n",
    "#                     break\n",
    "        \n",
    "#         os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(r\"C:\\Users\\aralmeida\\Downloads\\LibreViewRawData\\1yr_npy_files\\004\")\n",
    "\n",
    "# # Only read the OLDEST year of recording\n",
    "# recordings = np.load('oldest_1yr_CGM.npy')\n",
    "# timestamps = np.load('oldest_1yr_CGM_timestamp.npy', allow_pickle=True)\n",
    "\n",
    "# # Compute the differentce between two consecutive samples (in minutes)\n",
    "# time_diff = np.diff(timestamps)\n",
    "\n",
    "# # Empty array to fill with the values in minutes \n",
    "# time_diff_mins = np.empty(len(time_diff))\n",
    "\n",
    "# for i in range(0, len(time_diff_mins)): \n",
    "#     time_diff_mins[i] = (time_diff[i].seconds)//60 \n",
    "\n",
    "# # Plot all time intervals between two consecutive samples\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# # Plot \n",
    "# plt.plot(time_diff_mins)\n",
    "\n",
    "# # Horizontal line in 30 (2 consecutive samples)\n",
    "# plt.axhline(y=glucose_sensor[\"SAMPLE_PERIOD\"]*2, color='r', linestyle='-')\n",
    "\n",
    "# # Set X label\n",
    "# plt.xlabel('Sample difference')\n",
    "\n",
    "# # Set Y label\n",
    "# plt.ylabel('Minutes between sensor readings')\n",
    "\n",
    "# # Save figure\n",
    "# plt.savefig('sample_difference.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# # Find indexes where the difference between two consecutive samples is greater than 10 minutes\n",
    "# time_diff_idx = np.where(time_diff_mins >= glucose_sensor[\"SAMPLE_PERIOD\"]*2)\n",
    "\n",
    "# # Number of blocks in a patient are defined when two consecutive readings surpass 2*sensor[\"SAMPLE_PERIOD\"]\n",
    "# n_blocks = len(time_diff_mins[np.where(time_diff_mins >= glucose_sensor[\"SAMPLE_PERIOD\"]*2)])\n",
    "# print(\"Number of blocks of is %i\\n\" % (n_blocks))\n",
    "\n",
    "# # Step for the output value identification - 1: For N = 49, the output is 5 min (value 50) / 2: 10 min (value 51) / etc. \n",
    "# step = round(prediction_horizon/glucose_sensor[\"SAMPLE_PERIOD\"])\n",
    "\n",
    "# # Global index useful to extract the blocks for the original array\n",
    "# global_idx = 0 # 1 in matlab\n",
    "\n",
    "# # Numpy array to count samples in each block\n",
    "# num_samples = np.zeros((n_blocks, 1))\n",
    "\n",
    "# # List to store the indexes X and Y (faster computation than concatenate arrays)\n",
    "# X_init_list = []\n",
    "# X_end_list = []\n",
    "# Y_init_list = []\n",
    "# Y_end_list = []\n",
    "\n",
    "# for i in range(0, n_blocks):\n",
    "\n",
    "#     # Compute size of the current block\n",
    "#     block_size = time_diff_idx[0][i]-global_idx\n",
    "    \n",
    "#     if verbose == 1:\n",
    "#         print(\"Block size is %i\" % (block_size))\n",
    "    \n",
    "#     # Loop until the last value possible value of the block considering N\n",
    "#     for j in range(0, round(block_size - N - step)):\n",
    "\n",
    "#         # Reference value for the initial data point to be collected \n",
    "#         X_init_list.append(global_idx+j)\n",
    "\n",
    "#         # Reference value for the last data point to be collected \n",
    "#         X_end_list.append(global_idx+j+N)\n",
    "\n",
    "#         # Reference value for the initial Y point to be collected \n",
    "#         Y_init_list.append(global_idx+j+N)\n",
    "\n",
    "#         # Reference value for the last data point to be collected \n",
    "#         Y_end_list.append(global_idx+j+N+step)\n",
    "\n",
    "#         # Count the samples of the current block\n",
    "#         num_samples[i] = j+1\n",
    "\n",
    "#     # Print number of samples \n",
    "#     if verbose == 1:\n",
    "#         print(\"Number of samples in block %i is %i\\n\" % ((i+1), num_samples[i]))\n",
    "\n",
    "#     # Update the global index\n",
    "#     global_idx = time_diff_idx[0][i] \n",
    "\n",
    "# # Declare X an Y vector with all time and glucose concatenated data to further processing\n",
    "# X = np.zeros((len(X_init_list), N), dtype=np.float32)\n",
    "# Y = np.zeros((len(Y_init_list), round(prediction_horizon/glucose_sensor[\"SAMPLE_PERIOD\"])), dtype=np.float32) # Check values on sensor_params.py and arch_params.py\n",
    "# X_times = np.empty((len(X_init_list), N), dtype='datetime64[s]')\n",
    "# Y_times = np.empty((len(Y_init_list), round(prediction_horizon/glucose_sensor[\"SAMPLE_PERIOD\"])), dtype='datetime64[s]')\n",
    "\n",
    "# for i in range(0, X.shape[0]):\n",
    "#     X[i,:] = recordings[X_init_list[i] : X_end_list[i]]\n",
    "#     Y[i,:] = recordings[Y_init_list[i] : Y_end_list[i]]\n",
    "#     X_times[i,:] = timestamps[X_init_list[i] : X_end_list[i]]\n",
    "#     Y_times[i] = timestamps[Y_init_list[i] : Y_end_list[i]] \n",
    "\n",
    "# # Save training dataset summary in a txt file\n",
    "# with open('dataset_summary.txt', 'w') as f:\n",
    "#     f.write('N = {}\\n'.format(N))\n",
    "#     f.write('step = {}\\n'.format(step))\n",
    "#     f.write('PH = {}\\n'.format(prediction_horizon))\n",
    "#     f.write('sensor = {}\\n'.format(glucose_sensor['NAME']))\n",
    "#     f.write('nº blocks = {}\\n'.format(n_blocks))\n",
    "\n",
    "# # Export X, Y and associated times as .npy files\n",
    "# np.save('X.npy', X)\n",
    "# np.save('Y.npy', Y)\n",
    "# np.save('X_times.npy', X_times)\n",
    "# np.save('Y_times.npy', Y_times) \n",
    "\n",
    "# # Convert np.arrays to float32 to convert them to Tensorflow tensors\n",
    "# X = X.astype(np.float32)\n",
    "# Y = Y.astype(np.float32)\n",
    "\n",
    "# # Timestamp of the fold 1 is the first of the whole recording \n",
    "# fold1_first_timestamp = X_times[0][0]\n",
    "\n",
    "# # Timestamp of the fold 2 is the first of the whole recording + 3 months\n",
    "# fold2_first_timestamp = fold1_first_timestamp + pd.DateOffset(months=3)\n",
    "\n",
    "# # Timestamp of the fold 3 is the first of the whole recording + 6 months\n",
    "# fold3_first_timestamp = fold1_first_timestamp + pd.DateOffset(months=6)\n",
    "\n",
    "# # Timestamp of the fold 4 is the first of the whole recording + 9 months\n",
    "# fold4_first_timestamp = fold1_first_timestamp + pd.DateOffset(months=9)\n",
    "\n",
    "# # With the timestamps, the 4 folds are generated\n",
    "# X_fold1 = X[np.where((X_times[:,0] >= fold1_first_timestamp) & (Y_times[:,0] < fold2_first_timestamp))[0]]\n",
    "# X_fold2 = X[np.where((X_times[:,0] >= fold2_first_timestamp) & (Y_times[:,0] < fold3_first_timestamp))[0]]\n",
    "# X_fold3 = X[np.where((X_times[:,0] >= fold3_first_timestamp) & (Y_times[:,0] < fold4_first_timestamp))[0]]\n",
    "# X_fold4 = X[np.where(X_times[:,0] >= fold4_first_timestamp)] \n",
    "\n",
    "# print(len(X_fold1))\n",
    "# print(len(X_fold2))\n",
    "# print(len(X_fold3))\n",
    "# print(len(X_fold4))\n",
    "\n",
    "\n",
    "# # Also save the timestamps of the fold just in case they are necessary \n",
    "# X_times_fold1 = X_times[np.where((X_times[:,0] >= fold1_first_timestamp) & (Y_times[:,0] < fold2_first_timestamp))[0]]\n",
    "# X_times_fold2 = X_times[np.where((X_times[:,0] >= fold2_first_timestamp) & (Y_times[:,0] < fold3_first_timestamp))[0]]\n",
    "# X_times_fold3 = X_times[np.where((X_times[:,0] >= fold3_first_timestamp) & (Y_times[:,0] < fold4_first_timestamp))[0]]\n",
    "# X_times_fold4 = X_times[np.where(X_times[:,0] >= fold4_first_timestamp)]\n",
    "\n",
    "# # Take the same instances from Y\n",
    "# Y_fold1 = Y[np.where((X_times[:,0] >= fold1_first_timestamp) & (Y_times[:,0] < fold2_first_timestamp))[0]]\n",
    "# Y_fold2 = Y[np.where((X_times[:,0] >= fold2_first_timestamp) & (Y_times[:,0] < fold3_first_timestamp))[0]]\n",
    "# Y_fold3 = Y[np.where((X_times[:,0] >= fold3_first_timestamp) & (Y_times[:,0] < fold4_first_timestamp))[0]]\n",
    "# Y_fold4 = Y[np.where(X_times[:,0] >= fold4_first_timestamp)]\n",
    "\n",
    "# vacio = recordings[np.where((timestamps >= fold4_first_timestamp))[0]]\n",
    "# vacio_timestamps = timestamps[np.where((timestamps >= fold4_first_timestamp))[0]]\n",
    "# print(len(X_fold4))\n",
    "# print(len(Y_fold4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if the folds are right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector = np.linspace(48,53,4)\n",
    "# random_int = np.random.randint(0, 2000)\n",
    "# print(random_int)\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"fold1\")\n",
    "# plt.plot(fold1_X_train[random_int,:], 'ro')\n",
    "# plt.plot(vector, fold1_Y_train[random_int,:], 'go')\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"fold2\")\n",
    "# plt.plot(fold2_X_train[random_int,:], 'ro')\n",
    "# plt.plot(vector, fold2_Y_train[random_int,:], 'go')\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"fold3\")\n",
    "# plt.plot(fold3_X_train[random_int,:], 'ro')\n",
    "# plt.plot(vector, fold3_Y_train[random_int,:], 'go')\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"fold4\")\n",
    "# plt.plot(fold4_X_train[random_int,:], 'ro')\n",
    "# plt.plot(vector, fold4_Y_train[random_int,:], 'go')\n",
    "\n",
    "\n",
    "# ######################### TEST DE COMPROBACION DE LOS FOLDS ##############################\n",
    "# a1 = X[np.where((X_times[:,0] >= fold2_first_timestamp) & (X_times[:,0] < fold3_first_timestamp))[0]]\n",
    "# aa1 = X[np.where((X_times[:,0] >= fold2_first_timestamp) & (Y_times[:,0] < fold3_first_timestamp))[0]]\n",
    "# X_fold3 = X[np.where((X_times[:,0] >= fold3_first_timestamp) & (X_times[:,0] < fold4_first_timestamp))[0]]\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"si no tenemos en cuenta al timestamp de Y\")\n",
    "# plt.plot(a1[3670], label = \"ultima inst. fold2\")\n",
    "# plt.plot(X_fold3[0], label = \"primera inst. fold3\")\n",
    "# plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"si  tenemos en cuenta al timestamp de Y\")\n",
    "# plt.plot(aa1[3639], label = \"ultima inst. fold2\")\n",
    "# plt.plot(X_fold3[0], label = \"primera inst. fold3\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if the output sequence is well-generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector = np.linspace(48,53,4)\n",
    "# plt.figure()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(X[4,:], 'ro')\n",
    "# plt.plot(vector, Y[4,:], 'go')\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(X[5,:], 'ro')\n",
    "# plt.plot(vector, Y[5,:], 'go')\n",
    "# plt.figure()\n",
    "# plt.plot(X[6,:], 'ro')\n",
    "# plt.plot(vector, Y[6,:], 'go')\n",
    "# plt.figure()\n",
    "# plt.plot(X[7,:], 'ro')\n",
    "# plt.plot(vector, Y[7,:], 'go')\n",
    "# plt.figure()\n",
    "# plt.plot(X[8,:], 'ro')\n",
    "# plt.plot(vector, Y[8,:], 'go')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "T1DM_WARIFA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
